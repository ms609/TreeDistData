---
title: "Tree Search with Profile Parsimony"
author: "Martin R. Smith"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: ../inst/REFERENCES.bib
csl: ../inst/apa-old-doi-prefix.csl
vignette: >
  %\VignetteIndexEntry{Tree search with profile parsimony}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

Profile Parsimony [@Faith2001] finds the tree that is most faithful 
to the information contained within a given dataset. 
It is the 'exact solution' that implied weights parsimony approximates.

Profile Parsimony is currently implemented in TreeSearch only 
for binary characters with no ambiguous tokens.

## Getting started
<!--Duplicated from inapplicable.Rmd-->
[A companion vignette](getting-started.html) gives details on installing 
the package and getting up and running.

<!--
# message=FALSE will suppress message when loading TreeSearch
# Temporary fix until R.oo is updated -- remove thereafter
# https://github.com/r-lib/rlang/issues/669
-->

Once installed, load the inapplicable package into R using
```{r Load-library, message=FALSE}
library('TreeSearch')
```

In order to reproduce the random elements of this document, set a random seed:

```{R RNG-version, warning=FALSE}
# Set a random seed so that random functions in this document are reproducible
RNGversion("3.5.0") # Until we can require R3.6.0
set.seed(888)
```


## Scoring a tree, and conducting a tree search

Here's an example of using the package to conduct tree search with profile 
parsimony.
You can [load your own dataset](load-data.html), but for this example,
we'll use a simulated dataset that comes bundled with the `TreeSearch` package.

```{r Load Longrich data}
data(congreveLamsdellMatrices)
my.data <- congreveLamsdellMatrices[[10]]
my.phyDat <- phangorn::phyDat(my.data, type='USER', levels=c(1, 2))
```

We then need to prepare our dataset for Profile Parsimony by calculating the 
information loss implied by each additional step in each character.
Ideally we'd pick a high value of precision (> 1e+06): this takes a while, 
but only needs doing once for each dataset of a given size.

```{r Prepare the data for analysis, warning=FALSE}
my.prepdata <- PrepareDataProfile(my.phyDat, precision=4e+04)
```

To start analysis, we need to load a starting tree.  We can do this at random:
```{r Random tree, eval=FALSE}
tree <- RandomTree(my.phyDat)
```

Or using a neighbour joining method, to start at a reasonably good tree:
```{r NJ Tree}
tree <- NJTree(my.phyDat)
par(mar=rep(0.25, 4), cex=0.75) # make plot easier to read
plot(tree)
```

Let's calculate this random tree's parsimony score,
then search for a better tree:

```{R Starting score}
ProfileScore(tree, my.prepdata)

better.tree <- ProfileTreeSearch(tree, my.prepdata, EdgeSwapper=RootedTBRSwap)
```

The parsimony ratchet [@Nixon1999] is better at finding globally optimal trees. `ProfileRatchet`
is a convenient wrapper for the underlying function `Ratchet`.
```{r longwinded, eval=FALSE}
# Longwinded approach:
better.tree <- Ratchet(better.tree, my.prepdata, searchHits=10, searchIter=100, ratchIter=5,
                       swappers=list(RootedTBRSwap, RootedSPRSwap, RootedNNISwap),
                       InitializeData=ProfileInitMorphy, CleanUpData=ProfileDestroyMorphy,
                       TreeScorer=ProfileScoreMorphy, Bootstrapper=ProfileBootstrap)
```

```{r Cached results of ratchet search, echo=FALSE}
# The ratchet search takes a little while to run,
# so I've cached its results
better.tree <- structure(list(edge = structure(c(23L, 23L, 24L, 25L, 26L, 26L, 
27L, 28L, 28L, 29L, 29L, 30L, 30L, 27L, 31L, 31L, 25L, 32L, 32L, 
33L, 33L, 34L, 34L, 35L, 35L, 36L, 36L, 37L, 37L, 38L, 38L, 39L, 
39L, 40L, 40L, 41L, 41L, 24L, 42L, 42L, 43L, 43L, 1L, 24L, 25L, 
26L, 13L, 27L, 28L, 14L, 29L, 15L, 30L, 17L, 16L, 31L, 18L, 19L, 
32L, 12L, 33L, 11L, 34L, 10L, 35L, 9L, 36L, 8L, 37L, 7L, 38L, 
6L, 39L, 5L, 40L, 4L, 41L, 3L, 2L, 42L, 20L, 43L, 22L, 21L), .Dim = c(42L, 
2L)), tip.label = c("1", "2", "3", "4", "5", "6", "7", "8", "9", 
"10", "11", "12", "19", "18", "17", "15", "16", "13", "14", "20", 
"21", "22"), Nnode = 21L), class = "phylo", order = "cladewise", score = -309.16150317298, hits = 2)
```

```{r Ratchet search, eval=FALSE}
# Equivalent, but less typing!
RootedSwappers <- list(RootedTBRSwap, RootedSPRSwap, RootedNNISwap)
better.tree <- ProfileRatchet(better.tree, my.prepdata,
                              swappers=RootedSwappers,
                              searchHits=10, searchIter=100, ratchIter=5)

```

Let's see the resultant tree, and its score

```{r Ratchet-search-results}
attr(better.tree, 'score')
par(mar=rep(0.25, 4), cex=0.75) # make plot easier to read
plot(better.tree)
```

The default parameters may not be enough to find the optimal tree; type 
`?Ratchet` to view all search parameters.

## View the results

In parsimony search, it is good practice to consider trees that are slightly suboptimal [@Smith2019].

Here, we'll take a consensus that includes all trees that are suboptimal by up to 1.5 bits.
To sample this region of tree space well, the trick is to use large values of 
`ratchHits` and `ratchIter`, and small values of `searchHits` and
`searchiter`, so that many runs don't quite hit the optimal tree.
In a serious study, you would want to sample many more than the 25 Ratchet hits (`ratchHits`) we'll take here.

```{R Suboptimal sampling}
suboptimals <- ProfileRatchet(better.tree, my.prepdata, 
                              swappers=list(RootedTBRSwap),
                              returnAll=TRUE, suboptimal=5, 
                              ratchHits=25, ratchIter=5000, 
                              bootstrapHits=15, bootstrapIter=450,
                              searchHits=10, searchIter=50)
```

Let's calculate and display a consensus tree that includes slightly suboptimal trees.
```{r Plot suboptimal consensus}
par(mar=rep(0.2, 4))
plot(my.consensus <- ape::consensus(suboptimals))
```


## References

